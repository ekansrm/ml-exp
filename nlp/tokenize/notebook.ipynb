{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'D:\\Work\\Project\\Project.DataScience\\model\\glove\\glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = '/mnt/DATA/glove.6B/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思路\n",
    "1.从glove文件生成一个word和偏移量的索引\n",
    "2.根据任务生成一个vocab\n",
    "3.根据vocab生成tokenizer和embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EMBEDDING_FILE = 'D:\\Work\\Project\\Project.DataScience\\model\\glove\\embedding.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_EMBEDDING_FILE = 'embedding.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成测试用的文件\n",
    "NUM_LINE = 100\n",
    "lines = []\n",
    "with open(glove_path, \"r\") as fp:\n",
    "    for i in range(NUM_LINE):\n",
    "        lines.append(fp.readline())\n",
    "\n",
    "with open(TEST_EMBEDDING_FILE, 'w') as fp:\n",
    "    fp.write('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查token是否发生变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查参数是否发生变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存文件\n",
    "import pickle\n",
    "\n",
    "\n",
    "def _save_var(var, filepath):\n",
    "    with open(file=filepath, mode=\"wb\") as fp:\n",
    "        pickle.dump(index, file=fp)\n",
    "    \n",
    "    \n",
    "def _load_var(filepath):\n",
    "    with open(file=filepath, mode=\"rb\") as fp:\n",
    "        return pickle.load(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0% | 0/260439 | [00:00<?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100% | 260439/260439 | [00:00<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: the\ncorrect: \n\ncorrect: ,\ncorrect: .\ncorrect: of\ncorrect: to\ncorrect: and\ncorrect: in\ncorrect: a\ncorrect: \"\ncorrect: 's\ncorrect: for\ncorrect: -\ncorrect: that\ncorrect: on\ncorrect: is\ncorrect: was\ncorrect: said\ncorrect: with\ncorrect: he\ncorrect: as\ncorrect: it\ncorrect: by\ncorrect: at\ncorrect: (\ncorrect: )\ncorrect: from\ncorrect: his\ncorrect: ''\ncorrect: ``\ncorrect: an\ncorrect: be\ncorrect: has\ncorrect: are\ncorrect: have\ncorrect: but\ncorrect: were\ncorrect: not\ncorrect: this\ncorrect: who\ncorrect: they\ncorrect: had\ncorrect: i\ncorrect: which\ncorrect: will\ncorrect: their\ncorrect: :\ncorrect: or\ncorrect: its\ncorrect: one\ncorrect: after\ncorrect: new\ncorrect: been\ncorrect: also\ncorrect: we\ncorrect: would\ncorrect: two\ncorrect: more\ncorrect: '\ncorrect: first\ncorrect: about\ncorrect: up\ncorrect: when\ncorrect: year\ncorrect: there\ncorrect: all\ncorrect: --\ncorrect: out\ncorrect: she\ncorrect: other\ncorrect: people\ncorrect: n't\ncorrect: her\ncorrect: percent\ncorrect: than\ncorrect: over\ncorrect: into\ncorrect: last\ncorrect: some\ncorrect: government\ncorrect: time\ncorrect: $\ncorrect: you\ncorrect: years\ncorrect: if\ncorrect: no\ncorrect: world\ncorrect: can\ncorrect: three\ncorrect: do\ncorrect: ;\ncorrect: president\ncorrect: only\ncorrect: state\ncorrect: million\ncorrect: could\ncorrect: us\ncorrect: most\ncorrect: _\ncorrect: against\ncorrect: u.s.\n101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 生成 index\n",
    "def _index(embedding):\n",
    "    index = {}\n",
    "    with open(embedding, 'r', encoding='utf-8') as fp:\n",
    "        linecnt = 0\n",
    "        word = ''\n",
    "        getword = False\n",
    "        fp.seek(0, 2)\n",
    "        filesize = fp.tell()\n",
    "        fp.seek(0, 0)\n",
    "        bar_format = \"{percentage:3.0f}% | {n_fmt}/{total_fmt} | [{elapsed}<{remaining}]\"\n",
    "        with tqdm.tqdm(total=filesize, bar_format=bar_format) as p_bar:\n",
    "            while True:\n",
    "                c = fp.read(1)\n",
    "                \n",
    "                # 如果不是最后一个字符\n",
    "                if c is not \"\":\n",
    "                    linecnt += 1\n",
    "                    \n",
    "                # word为第一个空格前的字符           \n",
    "                if getword is False:\n",
    "                    if c == \" \":\n",
    "                        getword = True\n",
    "                    else:\n",
    "                        word = word + c\n",
    "                \n",
    "                # 如果已经是最后一个字符, 或者遇到回车符\n",
    "                if c == '\\n' or c is \"\":\n",
    "                    if linecnt is not 0:\n",
    "                        index[word] = (fp.tell() - linecnt, linecnt)\n",
    "                    p_bar.update(linecnt)\n",
    "                    linecnt = 0\n",
    "                    getword = False\n",
    "                    word = ''\n",
    "                \n",
    "                if c is \"\":\n",
    "                    break\n",
    "   \n",
    "    '''\n",
    "    # 下面这段代码有问题, 每一行的大小都少算一个字节\n",
    "    with open(TEST_EMBEDDING_FILE, 'r') as fp:\n",
    "        for line in fp.readlines():\n",
    "            items = line.split(\" \")\n",
    "            word = items[0]\n",
    "            index[word] = (size_cnt, len(line))\n",
    "            size_cnt = size_cnt + len(line)\n",
    "    '''\n",
    "    \n",
    "    return index\n",
    "\n",
    "\n",
    "index = _index(TEST_EMBEDDING_FILE)\n",
    "\n",
    "\n",
    "def _check_index(embedding, index):\n",
    "    a = {}\n",
    "    b = {}\n",
    "    with open(embedding, 'r') as fp:\n",
    "        for line in fp.readlines():\n",
    "            items = line.split(\" \")\n",
    "            a[items[0]] = line\n",
    "    with open(embedding, 'r') as fp: \n",
    "        for k in index:\n",
    "            fp.seek(index[k][0], 0)\n",
    "            b[k] = fp.read(index[k][1])\n",
    "    \n",
    "    cont = 0\n",
    "    for k in a:\n",
    "        if a[k] != b[k]:\n",
    "            print(\"wrong: \" + k)\n",
    "            print(a[k])\n",
    "            print(b[k])\n",
    "        else:\n",
    "            cont += 1\n",
    "\n",
    "            print(\"correct: \" + k)\n",
    "    print(cont)\n",
    "    \n",
    "    \n",
    "_check_index(TEST_EMBEDDING_FILE, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据vocab生成tokenizer 和 embedding\n",
    "\n",
    "def build(vocab: list):\n",
    "    # 检查是否已经存在embedding cache file, 如果没有\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_var(index, \"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_l = _load_var(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = TEST_EMBEDDING_FILE\n",
    "\n",
    "def load_index():\n",
    "    index_file = embedding + \".index\"\n",
    "    return _load_var(index_file)\n",
    "\n",
    "def save_index(index):\n",
    "    index_file = embedding + \".index\"\n",
    "    _save_var(index, index_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2 = load_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取vector\n",
    "m_index = index\n",
    "m_embedding_fp = open(embedding, 'r')\n",
    "\n",
    "\n",
    "def _load_vec(word):\n",
    "    pos = m_index[word]\n",
    "    m_embedding_fp.seek(pos[0])\n",
    "    line = m_embedding_fp.read(pos[1])\n",
    "    items = line.split(\" \")\n",
    "    word_in_embedding_file = items[0]\n",
    "    if word_in_embedding_file != word:\n",
    "        raise Exception(\"index not correct\")\n",
    "    return list(map(float, items[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据vocab加载embedding\n",
    "\n",
    "m_token\n",
    "\n",
    "def build(vocab, cache=None):\n",
    "    if cache is not None:\n",
    "        m_my_embedding = cache\n",
    "        m_my_embedding_token = cache + \".token\"\n",
    "        m_my_embedding_src = cache\n",
    "        \n",
    "        with open(file=m_my_embedding_token)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
