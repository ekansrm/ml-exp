{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = '/mnt/WORK/Project.DataScience/ml-exp/nlp/app/data1.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_batch = []\n",
    "with open(test_data_path, 'r', encoding='utf-8') as fp:\n",
    "    one_batch = []\n",
    "    for line in fp.readlines():\n",
    "        line = line.strip()\n",
    "        one_batch.append(line)\n",
    "        if '' == line:\n",
    "            test_data_batch.append(one_batch)\n",
    "            one_batch = []\n",
    "            continue\n",
    "    if 0 != len(one_batch):\n",
    "        test_data_batch.append(one_batch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_batch_size = [len(batch) for batch in test_data_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 13, 11, 16, 10, 18, 12, 15, 7, 17, 18, 12, 21, 21, 27, 30, 17, 51, 20, 23, 12, 30, 36, 12, 34, 17, 28, 30, 38, 18, 28, 12, 18, 26, 21, 10, 6, 45, 7, 16, 13, 21, 25, 11, 15, 21, 30, 28, 20, 20, 11, 6, 14, 13, 7, 9, 11, 17, 9, 11, 18, 27, 35, 23, 11, 39, 22, 7, 8, 7, 7, 10, 7, 7, 11, 22, 11, 14, 14, 23, 7, 14, 10, 11, 15, 12, 11, 20, 18, 8, 11, 23, 10]\n"
     ]
    }
   ],
   "source": [
    "print(test_data_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二元打分\n",
    "def score_binary(pos1, pos2):\n",
    "    return 1 if pos1 < pos2 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 句子抽取\n",
    "# 我们认为, 只有相邻的句子才有相关性\n",
    "# 句子的取法为:\n",
    "#   给定一个窗口长度\n",
    "#   从中抽取句子对\n",
    "#   \n",
    "\n",
    "from functools import reduce\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "    \n",
    "random.seed(time.time())\n",
    "\n",
    "def random_sample_key(m, w, n, k, unique=True):\n",
    "    \"\"\"\n",
    "    随机从m个样本中取出k个排列, 每个排列大小是n, 要求不重复\n",
    "    :param m: \n",
    "    :param n: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # 首先, 全排列的个数为 m*(m-1)...*(m-n+1) 如果超过这个数, 是不可能不重复的\n",
    "    if w < n:\n",
    "        raise RuntimeError(\"样本序列长度不能超过窗口长度\")\n",
    "    \n",
    "    # 首先, 每个窗口的全排列的总数是\n",
    "    full_permutation_num_per_window = reduce(lambda x, y: x*y, range(w-n+1, w+1))\n",
    "    \n",
    "    # TODO 实际上真实的样本空间比这个大, 但先用小的进行计算\n",
    "    total_sampling_space_size = (m//w) * full_permutation_num_per_window\n",
    "    \n",
    "    if k > total_sampling_space_size:\n",
    "        return []\n",
    "    \n",
    "    # 先随机生产取样窗口, \n",
    "    \n",
    "    windows_b = list(range(0, m-w)) \n",
    "    random.shuffle(windows_b)\n",
    "\n",
    "    sample_set = set()\n",
    "    # 随机地去窗口, 生成全排列, 加入到样本序列集里\n",
    "    i = 0\n",
    "    while i < len(windows_b):\n",
    "        w_b = windows_b[i]\n",
    "        w_e = w_b + w\n",
    "        for s in itertools.permutations(range(w_b, w_e), n):\n",
    "            sample_set.add(s)\n",
    "            if len(sample_set) >= k:\n",
    "                return list(sample_set)\n",
    "        i += 1\n",
    "    \n",
    "    return list(sample_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 7), (1, 3), (4, 8), (5, 6), (2, 1), (0, 3), (8, 5), (2, 4), (5, 8), (1, 2), (6, 7), (7, 6), (0, 4), (8, 6), (6, 4), (5, 4), (4, 5), (1, 4), (7, 5), (2, 3), (8, 7), (1, 0), (6, 5), (0, 1), (4, 6), (6, 8), (5, 7), (7, 4), (2, 0), (7, 8), (0, 2), (8, 4)]\n"
     ]
    }
   ],
   "source": [
    "print(random_sample_key(10, 5, 2, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusToSample(corpus, batch_size, score_func):\n",
    "    return [\n",
    "        (corpus[a], corpus[b], score_func(a, b)) \n",
    "        for a, b in random_sample_key(len(corpus), 5, 2, batch_size)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_data_batch:\n",
    "    # print(corpusToSample(batch, 32, score_binary))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "structed_test_data = [corpusToSample(batch, 32, score_binary) for batch in test_data_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 将数据拆分为6个输入\n",
    "\n",
    "def slice(x: str):\n",
    "    items = x.split(\"|\")\n",
    "    dep = items[0::3]\n",
    "    op1 = items[1::3]\n",
    "    op2 = items[2::3]\n",
    "    # tokenizer\n",
    "    # embedding\n",
    "\n",
    "    return dep, op1, op2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "\n",
    "def process_sample(batch):\n",
    "    \"\"\"\n",
    "    [(sentence1, sentence2, y)]\n",
    "    :param batch: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    dep_a = []\n",
    "    op1_a = []\n",
    "    op2_a = []\n",
    "    dep_b = []\n",
    "    op1_b = []\n",
    "    op2_b = []\n",
    "    y = []\n",
    "    for (sentence1, sentence2, _y) in batch:\n",
    "        _dep_a, _op1_a, _op2_a = slice(sentence1)\n",
    "        _dep_b, _op1_b, _op2_b = slice(sentence2)\n",
    "        dep_a.extend(_dep_a)\n",
    "        dep_b.extend(_dep_b)\n",
    "        op1_a.extend(_op1_a)\n",
    "        op1_b.extend(_op1_b)\n",
    "        op2_a.extend(_op2_a)\n",
    "        op2_b.extend(_op2_b)\n",
    "        y.append(_y)\n",
    "\n",
    "    return dep_a, op1_a, op2_a, dep_b, op1_b, op2_b, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取依存标签个数\n",
    "\n",
    "dep_set = set()\n",
    "vocab = set()\n",
    "\n",
    "for batch in structed_test_data:\n",
    "    dep_a, op1_a, op2_a, dep_b, op1_b, op2_b, y = process_sample(batch)\n",
    "    dep_set.update(dep_a)\n",
    "    dep_set.update(dep_b)\n",
    "    vocab.update(op1_a)\n",
    "    vocab.update(op1_b)\n",
    "    vocab.update(op2_b)\n",
    "    vocab.update(op2_a)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WP', 'LAD', 'DBL', 'POB', 'VOB', 'SBV', 'ATT', 'ADV', 'RAD', 'FOB', 'COO', 'IOB', 'CMP'}\n5055\n"
     ]
    }
   ],
   "source": [
    "print(dep_set)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "dep_token = defaultdict(lambda :0)\n",
    "\n",
    "dep_token.update(\n",
    "    \n",
    "    {\n",
    "    'SBV': 1,   #\t主谓关系\tsubject-verb\t我送她一束花 (我 <-- 送)\n",
    "    'VOB': 2,   #\t动宾关系\t直接宾语，verb-object\t我送她一束花 (送 --> 花)\n",
    "    'IOB': 3,   #\t间宾关系\t间接宾语，indirect-object\t我送她一束花 (送 --> 她)\n",
    "    'FOB': 4,   #\t前置宾语\t前置宾语，fronting-object\t他什么书都读 (书 <-- 读)\n",
    "    'DBL': 5,   #\t兼语\tdouble\t他请我吃饭 (请 --> 我)\n",
    "    'ATT': 6,   #\t定中关系\tattribute\t红苹果 (红 <-- 苹果)\n",
    "    'ADV': 7,   #\t状中结构\tadverbial\t非常美丽 (非常 <-- 美丽)\n",
    "    'CMP': 8,   #\t动补结构\tcomplement\t做完了作业 (做 --> 完)\n",
    "    'COO': 9,   #\t并列关系\tcoordinate\t大山和大海 (大山 --> 大海)\n",
    "    'POB': 10,  #\t介宾关系\tpreposition-object\t在贸易区内 (在 --> 内)\n",
    "    'LAD': 11,  #\t左附加关系\tleft adjunct\t大山和大海 (和 <-- 大海)\n",
    "    'RAD': 12,  #\t右附加关系\tright adjunct\t孩子们 (孩子 --> 们)\n",
    "    'IS':  13,  #\t独立结构\tindependent structure\t两个单句在结构上彼此独立\n",
    "    'WP':  14,  #\t标点符号\tpunctuation\t标点符号\n",
    "    'HED': 15,  #\t核心关系\thead\t指整个句子的核心\n",
    "}\n",
    ")\n",
    "\n",
    "def dep_tokenizer(dep):\n",
    "    return dep_token[dep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(dep_tokenizer('VOB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp.embedding import SimpleEmbeddingBuilder\n",
    "SimpleEmbeddingBuilder = SimpleEmbeddingBuilder.SimpleEmbeddingBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "custom embedding cache not found\n"
     ]
    }
   ],
   "source": [
    "embedding_builder = SimpleEmbeddingBuilder(\n",
    "    '/mnt/WORK/Project.DataScience/data/glove/glove.840B.300d.txt')\n",
    "\n",
    "embedding, tokenizer = embedding_builder.build(vocab, cache='embedding_test_model_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
